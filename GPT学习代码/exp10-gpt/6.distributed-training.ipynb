{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f03fc71-fda8-41c8-892e-342991c427f9",
   "metadata": {},
   "source": [
    "# Distributed training with Accelerate\n",
    "As models get bigger, **parallelism** has emerged as a strategy for **training larger models on limited hardware and accelerating training speed** by several orders of magnitude.\n",
    "\n",
    "HuggingFace created the Accelerate library to help users easily train a Transformers model on any type of distributed setup, whether it is **multiple GPU’s on one machine** or **multiple GPU’s across several machines**.\n",
    "\n",
    "In this tutorial, we will learn how to customize our native PyTorch training loop to enable training in a distributed environment.\n",
    "\n",
    "We get start by importing and creating an Accelerator object. The Accelerator will automatically detect our type of distributed setup and initialize all the necessary components for training. You don’t need to explicitly place your model on a device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a4293b-e78a-489b-9462-abc8c0063c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb99aa4-0bcc-4e7d-b755-451bddd35c33",
   "metadata": {},
   "source": [
    "## Prepare to accelerate\n",
    "The next step is to pass all the relevant training objects to the prepare method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5501f86e-c003-4aa3-beb4-c5173431a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n",
    "    train_dataloader, eval_dataloader, model, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db798197-4360-4197-b0c9-a6b19f19cdab",
   "metadata": {},
   "source": [
    "Your training dataloader will be sharded across all GPUs/TPU cores available so that each one sees a different portion of the training dataset.\n",
    "\n",
    "Also, the random states of all processes will be synchronized at the beginning of each iteration through your dataloader, to make sure the data is shuffled the same way (if you decided to use shuffle=True or any kind of random sampler).\n",
    "\n",
    "> The actual batch size for your training will be the number of devices used multiplied by the batch size you set in your script: for instance training on 4 GPUs with a batch size of 16 set when creating the training dataloader will train at an actual batch size of 64.\n",
    "\n",
    "Alternatively, you can use the option <code>split_batches=True</code> when creating and initializing your <code>Accelerator</code>, in which case the batch size will always stay the same, whether you run your script on 1, 2, 4, or 64 GPUs.\n",
    "\n",
    "You may or may not want to send your validation dataloader to prepare(), depending on whether you want to run distributed evaluation or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3cb804-ac0d-415d-b3be-6b0738bbdc77",
   "metadata": {},
   "source": [
    "## Backward\n",
    "The last addition is to replace the typical loss.backward() in your training loop with Accelerate’s backward method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858dbcf-896d-4d84-be4e-857dd8c3b8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)  # I'm here!\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c2be4-02c8-4878-b905-7df0e12600d9",
   "metadata": {},
   "source": [
    "We only need to add four additional lines of code to our training loop to enable distributed training!\n",
    "\n",
    "The overall code is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae95feb5-e94e-48b4-af2e-c01847b2e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler, AutoTokenizer\n",
    "\n",
    "\n",
    "def training():\n",
    "\n",
    "    # Initialize the Accelerator object for distributed training\n",
    "    accelerator = Accelerator()\n",
    "    \n",
    "    # Load the pretrained model, tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "    \n",
    "    # Define the AdamW optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "\n",
    "    # Define a function to tokenize the text examples\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "        \n",
    "    # Load the yelp review dataset and apply the tokenizer\n",
    "    dataset = load_dataset(\"yelp_review_full\")\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "    small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "    \n",
    "    # Create data loaders for training and evaluation\n",
    "    train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=16)\n",
    "    eval_dataloader = DataLoader(small_eval_dataset, batch_size=16)\n",
    "    \n",
    "    # Prepare the model, optimizer, and data loaders for distributed training\n",
    "    train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n",
    "        train_dataloader, eval_dataloader, model, optimizer\n",
    "    )\n",
    "    \n",
    "    # Set the number of epochs and the learning rate scheduler\n",
    "    num_epochs = 3\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "      \"linear\",\n",
    "      optimizer=optimizer,\n",
    "      num_warmup_steps=0,\n",
    "      num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    # Create a progress bar to track the training steps\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    # Load the accuracy metric\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # In training mode\n",
    "        model.train()\n",
    "        \n",
    "        # Loop over the batches in the training data loader\n",
    "        for batch in train_dataloader:\n",
    "            # Forward pass: compute the model outputs and loss\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass: compute the gradients using Accelerator's backward method\n",
    "            accelerator.backward(loss)\n",
    "    \n",
    "            # Update the model parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            # Zero out the gradients for the next batch\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "        # In evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Perform evaluation every epoch\n",
    "        for batch in eval_dataloader:\n",
    "            # Forward pass: compute the prediction digits\n",
    "            outputs = model(**batch)\n",
    "            # Gather all predictions and targets\n",
    "            all_outputs, all_labels = accelerator.gather_for_metrics((outputs, batch['labels']))\n",
    "            # Get the predictions from the logits\n",
    "            all_logits = all_outputs.logits\n",
    "            all_predictions = torch.argmax(all_logits, dim=-1)\n",
    "            # Example of use with a *Datasets.Metric*\n",
    "            metric.add_batch(predictions=all_predictions, references=all_labels)\n",
    "\n",
    "        # Compute the metric value over all batches and update the progress bar\n",
    "        progress_bar.set_postfix({'Accuracy': metric.compute()['accuracy']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83353a-724c-45c3-a308-53210cb73489",
   "metadata": {},
   "source": [
    "## Train\n",
    "Once you’ve added the relevant lines of code, launch your training in a script or a notebook.\n",
    "\n",
    "### Train with a script\n",
    "If you are running your training from a script, run the following command to create and save a configuration file:\n",
    "```\n",
    "accelerate config\n",
    "```\n",
    "Reply to the questions asked, and this will save a default_config.yaml file in your cache folder, default to be here: <code>~/.cache/huggingface/accelerate</code>. You can also specify with the flag --config_file the location of the file you want to save.\n",
    "\n",
    "Once this is done, you can test everything is going well on your setup by running:\n",
    "\n",
    "```\n",
    "accelerate test\n",
    "```\n",
    "This will launch a short script that will test the distributed environment. If it runs fine, you are ready for the next step!\n",
    "\n",
    "Then launch your training with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e4df10-f8c2-4a43-a03b-0ed897000fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/zonghang/.conda/envs/gpt/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/zonghang/.conda/envs/gpt/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Found cached dataset yelp_review_full (/home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 412.78it/s]\n",
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-07db653c92ff43bf.arrow\n",
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-9dc280153e031684.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-d5aa23cd04771b67.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-159efa9063e709af.arrow\n",
      "Found cached dataset yelp_review_full (/home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 400.37it/s]\n",
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-07db653c92ff43bf.arrow\n",
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-9dc280153e031684.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-d5aa23cd04771b67.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-159efa9063e709af.arrow\n",
      "100%|███████████████████████████| 96/96 [00:30<00:00,  3.13it/s, Accuracy=0.596]\n",
      "100%|███████████████████████████| 96/96 [00:30<00:00,  3.13it/s, Accuracy=0.596]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch distributed-training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0697d1-2ada-458c-afde-572f6cfe9a0a",
   "metadata": {},
   "source": [
    "If you stored the config file in a non-default location, you can indicate it to the launcher like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8d559e-3ee1-4fbc-b073-d6fc3b59c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate launch distributed-training.py --config_file path_to_config.yaml --args_for_the_script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44cf88a-a6cd-4f18-a940-eb73c4cb038c",
   "metadata": {},
   "source": [
    "To see the complete list of args parameters that you can pass in, run\n",
    "```\n",
    "accelerate launch -h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b7e20d-1922-476a-ae73-7dd732e7be63",
   "metadata": {},
   "source": [
    "### Train with a notebook\n",
    "Accelerate can also run in a notebook. Wrap all the code responsible for training in a function, and pass it to notebook_launcher.\n",
    "\n",
    "> The Accelerator object should only be defined inside the training function. This is because the initialization should be done inside the launcher only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "525ae030-6978-4df3-a7aa-fd7000c94dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/zonghang/.conda/envs/gpt/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/zonghang/.conda/envs/gpt/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Found cached dataset yelp_review_full (/home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f365d47e29f4b4194b6a3becddad42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (/home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n",
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-70c092b3ee550def.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a31172b6ba040dea1e58040739b764d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-70c092b3ee550def.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-8892a45b941239e8.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-8892a45b941239e8.arrow\n",
      "Loading cached shuffled indices for dataset at /home/zonghang/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-f9b53c5c2da8d38a.arrow\n",
      "100%|███████████████████████████| 96/96 [00:49<00:00,  1.92it/s, Accuracy=0.585]\n",
      "100%|███████████████████████████| 96/96 [00:49<00:00,  1.92it/s, Accuracy=0.585]\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "notebook_launcher(training, num_processes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51607cfa-5a00-4007-88d6-5445de55c530",
   "metadata": {},
   "source": [
    "## Distributed evaluation\n",
    "You can perform regular evaluation in your training script, if you leave your validation dataloader out of the prepare() method. In this case, you will need to put the input data on the accelerator.device manually.\n",
    "\n",
    "To perform distributed evaluation, send along your validation dataloader to the prepare() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9c2f6-3b10-4a79-b9bf-ac6b5a3f6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = accelerator.prepare(eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eba520-db75-44c1-b863-3612bb6ff292",
   "metadata": {},
   "source": [
    "As each device will only see part of the evaluation data, you will need to group your predictions together. This is very easy to do with the gather_for_metrics() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642aabde-ac12-4e18-ae00-4d9160020ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in eval_dataloader:\n",
    "    # Forward pass: compute the prediction digits\n",
    "    outputs = model(**batch)\n",
    "    # Gather all predictions and labels\n",
    "    all_outputs, all_labels = accelerator.gather_for_metrics((outputs, batch['labels']))\n",
    "    # Get the predictions from the logits\n",
    "    all_logits = all_outputs.logits\n",
    "    all_predictions = torch.argmax(all_logits, dim=-1)\n",
    "    # Example of use with a *Datasets.Metric*\n",
    "    metric.add_batch(predictions=all_predictions, references=all_labels)\n",
    "\n",
    "# Compute the metric value over all batches\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12b65a1-181c-4470-9577-03eee852fac8",
   "metadata": {},
   "source": [
    "> Similar to the training dataloader, passing your validation dataloader through prepare() may change it: if you run on X GPUs, it will have its length divided by X (since your actual batch size will be multiplied by X), unless you set <code>split_batches=True</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d80a13-0b66-4488-b73f-303dbfd22a1d",
   "metadata": {},
   "source": [
    "## Other caveats\n",
    "### Execute a statement only on one processes\n",
    "Some of your instructions only need to run for one process on a given server: for instance a data download or a log statement. To do this, wrap the statement in a test like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1587011a-4f60-43f7-b4d0-2706d47c9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_local_main_process:\n",
    "    # Is executed once per server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8660fdd7-f8a5-4811-ab3d-e6eb090b9583",
   "metadata": {},
   "source": [
    "Another example is progress bars: to avoid having multiple progress bars in your output, you can display one only on the local main process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab323a-4a9e-4064-9e9c-edc17617e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b8b15-26b9-4406-b43b-af93399e76aa",
   "metadata": {},
   "source": [
    "The local means per machine: if you are running your training on two servers with several GPUs, the instruction will be executed once on each of those servers. If you need to execute something only once for all processes (and not per machine), wrap it in a test like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc9ca78-be40-42d4-bbbe-475969f0c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "    # Is executed once only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58286ac1-7395-46da-87fd-b9399cae4583",
   "metadata": {},
   "source": [
    "For printing statements, if you only want to execut it once per machine, you can just replace the print function by <code>accelerator.print</code>.\n",
    "\n",
    "### Defer execution\n",
    "When you run your usual script, instructions are executed in order. Using Accelerate to deploy your script on several GPUs at the same time introduces a complication: while each process executes all instructions in order, some may be faster than others.\n",
    "\n",
    "You might need to **wait for all processes to have reached a certain point before executing a given instruction**. For instance, you shouldn’t save a model before being sure every process is done with training. \n",
    "\n",
    "To do this, just write the following line in your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b7014-0257-4f3a-9698-853a42ae6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac26d1f-f88a-445b-84d2-f43a7f4b576d",
   "metadata": {},
   "source": [
    "This instruction will block all the processes that arrive first until all the other processes have reached that point (if you run your script on just one GPU or CPU, this won’t do anything)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68c47f-543f-43a0-81d4-c1eec998ce5a",
   "metadata": {},
   "source": [
    "### Saving/loading a model\n",
    "Saving the model you trained might need a bit of adjustment: first you should **wait for all processes to reach that point** in the script as shown above, and then, you should **unwrap your model** before saving it.\n",
    "\n",
    "This is because when going through the prepare() method, your model may have been placed inside a bigger model, which deals with the distributed training. This in turn means that saving your model state dictionary without taking any precaution will take that potential extra layer into account, and you will end up with weights you can’t load back in your base model.\n",
    "\n",
    "This is why it’s recommended to unwrap your model first. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1cfea-7ea4-4746-8fb6-1c02c194c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator.wait_for_everyone()\n",
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "accelerator.save(unwrapped_model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf50f8e-1543-479f-a865-7f3d9ac6d16a",
   "metadata": {},
   "source": [
    "If your script contains logic to load a checkpoint, we also recommend you load your weights in the unwrapped model (this is only useful if you use the load function after making your model go through prepare()). \n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3d73b-02a3-4d81-b4f8-39c6208f9d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwrapped_model = accelerator.unwrap_model(model)\n",
    "unwrapped_model.load_state_dict(torch.load(filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
